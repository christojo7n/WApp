{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuaBt_N8bxYr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir \"/content/drive/MyDrive/CNNWMA/data/logs\""
      ],
      "metadata": {
        "id": "qX-YqtVDb6Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # change to your saved location\n",
        "%cd /content/drive/MyDrive/TL_WMA/data "
      ],
      "metadata": {
        "id": "MeGDaV6Ub75t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOLDER COUNT INCREMENT\n",
        "exp_sv_dir=''\n",
        "def inc_dir(fldr,occ):\n",
        "  runs=fldr\n",
        "  sv_dir= runs+'/exp_'+str(len(os.listdir(runs))+occ)\n",
        "  if(not os.path.exists(sv_dir)):\n",
        "    os.mkdir(sv_dir)\n",
        "    global exp_sv_dir\n",
        "    exp_sv_dir = sv_dir\n",
        "    return sv_dir\n",
        "  else:\n",
        "    print(\"path exist\")\n",
        "    inc_dir(runs,occ+1)\n",
        "\n",
        "#SETUP\n",
        "\n",
        "import os,tqdm\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "# CALL BACKS\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping ,ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "\n",
        "clsnm= ['Burn','Hematoma','Abscess','Abrasion','Cut/Incision']\n",
        "\n",
        "x_test=np.load(\"x_test.npy\")\n",
        "x_train=np.load(\"x_train.npy\")\n",
        "x_val=np.load(\"x_val.npy\")\n",
        "y_train=np.load(\"y_train.npy\")\n",
        "y_test=np.load(\"y_test.npy\")\n",
        "y_val=np.load(\"y_val.npy\")\n",
        "\n",
        "print(x_train.shape,y_train.shape)\n",
        "print(x_test.shape,y_test.shape)\n",
        "print(x_val.shape,y_val.shape)\n",
        "\n",
        "#HOT ONE ENCODE\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from tensorflow.keras.utils  import to_categorical\n",
        "\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)\n",
        "\n",
        "\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "metadata": {
        "id": "tz6iSlCAb89m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mdl_noaug = Sequential()\n",
        "mdl_noaug.add(Conv2D(32, (3, 3), input_shape=(227,227,3)))\n",
        "mdl_noaug.add(Activation('relu'))\n",
        "mdl_noaug.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "mdl_noaug.add(BatchNormalization())\n",
        "\n",
        "mdl_noaug.add(Conv2D(32, (3, 3)))\n",
        "mdl_noaug.add(Activation('relu'))\n",
        "mdl_noaug.add(MaxPooling2D(pool_size=(5, 5)))\n",
        "mdl_noaug.add(BatchNormalization())\n",
        "\n",
        "mdl_noaug.add(Conv2D(32, (3, 3)))\n",
        "mdl_noaug.add(Activation('relu'))\n",
        "mdl_noaug.add(MaxPooling2D(pool_size=(5, 5)))\n",
        "mdl_noaug.add(BatchNormalization())\n",
        "\n",
        "mdl_noaug.add(Flatten()) \n",
        "\n",
        "mdl_noaug.add(Dense(32))\n",
        "mdl_noaug.add(Activation('relu'))\n",
        "mdl_noaug.add(Dropout(0.6))\n",
        "\n",
        "mdl_noaug.add(Dense(5))\n",
        "mdl_noaug.add(Activation('softmax'))\n",
        "\n",
        "mdl_noaug.summary()\n"
      ],
      "metadata": {
        "id": "423Kf573b9pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model #NO AUG\n",
        "\n",
        "mdl_noaug.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "tb_callback = TensorBoard(log_dir=inc_dir(r\"/content/drive/MyDrive/CNNWMA/data/logs\",0))\n",
        "ml_best= exp_sv_dir + '/cjbest.h5'\n",
        "\n",
        "mc = ModelCheckpoint(ml_best, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n",
        "lrr= ReduceLROnPlateau( monitor='val_loss', factor=.1,  patience=5, min_lr=0.00001)\n",
        "\n",
        "epochs=300\n",
        "batch_size = 64\n",
        "%pwd\n",
        "mdl_noaug.fit(x_train, y_train, epochs = epochs,\n",
        "            validation_data = (x_val,y_val), \n",
        "            callbacks = [tb_callback,es,mc,lrr],verbose=1)\n",
        "\n",
        "print(exp_sv_dir)\n",
        "model_dir = exp_sv_dir+\"/cj_model.h5\"\n",
        "mdl_noaug.save(model_dir)\n",
        "his_dir = exp_sv_dir +'/cjnet_history.npy'\n",
        "np.save(his_dir,mdl_noaug.history)"
      ],
      "metadata": {
        "id": "dE4eTQp4cBO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        " \n",
        "#GRAPHS & TESTING\n",
        "\n",
        "#num=9\n",
        "#svd_pth = r\"/content/drive/MyDrive/CNNWMA/data/logs\" #seeting directory\n",
        "#svd_model= svd_pth+'/exp_'+str(num)+'/cjbest.h5' #setting file path\n",
        "\n",
        "C7NET = load_model(\"cjbest.h5\")\n",
        "print(svd_model)\n",
        "\n",
        "\n",
        "#svd_his= svd_pth+'/exp_'+str(num) +'/cjnet_history.npy'\n",
        "C7his=np.load(\"cjnet_history.npy\",allow_pickle='TRUE').item()\n",
        "#After successful training, we will visualize its performance.\n",
        "#print(svd_his)\n",
        "\n",
        "\n",
        "predict_x=C7NET.predict(x_test) \n",
        "y_pred=np.argmax(predict_x,axis=1)\n",
        "y_true=np.argmax(y_test,axis=1)\n",
        "\n",
        "acc_score = accuracy_score(y_true, y_pred)\n",
        "print('Accuracy Score = ', acc_score)\n",
        "\n",
        "\n",
        "\n",
        "#Plotting the training and validation loss\n",
        "\n",
        "f,ax=plt.subplots(1,2) #Creates 2 subplots under 1 column\n",
        "f.set_figwidth(17)\n",
        "f.set_figheight(8)\n",
        "\n",
        "#Assigning the first subplot to graph training loss and validation loss\n",
        "ax[0].plot(C7his.history['loss'][20:],color='b',label='Training Loss')\n",
        "ax[0].plot(C7his.history['val_loss'][20:],color='r',label='Validation Loss')\n",
        "ax[0].legend()\n",
        "\n",
        "#Plotting the training accuracy and validation accuracy\n",
        "ax[1].plot(C7his.history['accuracy'],color='b',label='Training  Accuracy')\n",
        "ax[1].plot(C7his.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "C7NET.summary()"
      ],
      "metadata": {
        "id": "RV__e2KGcHjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CONFUSION MATRIX\n",
        "#Defining function for confusion matrix plot\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "#Print Confusion matrix\n",
        "    fig, ax = plt.subplots(figsize=(7,7))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "#Plotting the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#confusion_mtx=confusion_matrix(y_true,y_pred)\n",
        "\n",
        "clsnm= ['Burn','Hematoma','Abscess','Abrasion','Cut/Incision']\n",
        "\n",
        "# Plotting non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_true, y_pred, classes = clsnm,title = 'Confusion matrix, Normalized',normalize=True)"
      ],
      "metadata": {
        "id": "1wmMG51bchJp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}